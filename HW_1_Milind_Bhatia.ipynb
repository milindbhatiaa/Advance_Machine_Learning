{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voAS4e-XbWaH"
      },
      "source": [
        "#Assignment - 1\n",
        "\n",
        "###Due: 11:59 PM CT, September 7\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1QeRVC6S-X2"
      },
      "source": [
        "MIS 382N: ADVANCED MACHINE LEARNING\n",
        "\n",
        "Assignment 1\n",
        "\n",
        "Total points: 70\n",
        "\n",
        "Due: Wednesday, September 7 submitted via Canvas by 11:59 pm\n",
        "\n",
        "Your homework should be written in a Python notebook. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas. But be sure to include name and UT EID for both students.\n",
        "\n",
        "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh_WVVdznfMN"
      },
      "source": [
        "# Question 1: Adoption of AI/ML (5 pts)\n",
        "\n",
        "Read the HBR article on barriers to adoption of AI/ML based solutions in the healthcare industry, which is posted as the first document in Canvas under Modules --> Resources.\n",
        "\n",
        "Write a paragraph in your own words summarizing what you feel were the key factors that contributed to the lack of trust (and hence adoption) of the AI/ML solutions discussed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkVxrWs0o0tn"
      },
      "source": [
        "\n",
        "# Question 2: Google Flu Trends (8 pts)\n",
        "\n",
        "The second article posted  in Canvas under Modules --> Resources, (google flu) describes a high-profile (and embarrassingly  failed)  project done by google, highlighting the phenomena of data drift and the importance of continually monitoring/updating models post deployment.\n",
        "\n",
        "Read this article and then briefly describe\n",
        "\n",
        "(i) three important causes of \"data drift\" in the flu prediction problem that are mentioned in the article, and\n",
        "\n",
        "(ii) one important aspect of the original google model design that made it very prone to overfitting (and hence poor generalization on future data).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpTvwLiHVmfo"
      },
      "source": [
        "# Question 3: Maximum Likelihood Estimate (12 pts)\n",
        "\n",
        "100 students in the MSBA Program were asked if they wanted to buy the Big Ticket for the season. They reported their preferences by entering No or Yes in the survey. We use 0 to represent their disinterest in buying the Big Ticket and 1 to represent their interest. A random sample of 30 students yielded the following preferences:\n",
        "\n",
        "$$0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 1$$\n",
        "\n",
        "These choices are assumed to arise by independent and identically distributed (i.i.d.) sampling from the following distribution and if the unknown parameter $q$ can be estimated, then we can provide more insights about the students' preference.\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\nonumber P(x) = \\left\\{\n",
        "\\begin{array}{l l}\n",
        "    q& \\quad \\text{for  } x=0\\\\\n",
        "1-q & \\quad \\text{for } x=1\n",
        "\\end{array} \\right.\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "\n",
        "1. Based on the definitions given above, write down the likelihood function (3 pts)\n",
        "2. Derive the **maximum likelihood estimator** of $q$ (Algenric expression in terms of variables) (3 pts)\n",
        "3. Using the given sample, find a maximum likelihood estimate of $q$ as well (numerical value) (3 pts)\n",
        "4. Show that the maximum likelihood estimate is unbiased (3 pts)\n",
        "\n",
        "Note: For this question, you can either upload a scanned copy of the handwritten solution or write the answer in LaTex/Markdown.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTWFVcvwXP4w"
      },
      "source": [
        "# Question 4: Linear Regression (10 pts)\n",
        "\n",
        "1. What is the difference between R-square and adjusted R square and why is it desirable to use the adjusted value? (4 pts)\n",
        "\n",
        "2. Overfitting usually happens in complex models. Linear Regression is a fairly simple model. Could overfitting happen in Linear Regression? If so, please explain the scenario in which it could happen and how we can tackle it. (6 pts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvIs1fklzWoY"
      },
      "source": [
        "# Question 5: Ridge/ Lasso Regression (35 pts)\n",
        "\n",
        "This is a programming question. Please read through each subpart of this question carefully. You are required to add lines of code as specified in the code cells. Please carefully read through the comments in the code cells to identify what code is to be written, where it is to be written and how many lines of code are required. Code is to be added between the **## START CODE** ## and **## END CODE ##** comments and in place of the keyword **None**. In certain cases, the number of lines of code that are to be written will be specified. For example, **## START CODE ## (1 line of code)** specifies that only 1 line of code is to be added between the ## START CODE ## and ## END CODE ## comments. In case there is no information on the required number of lines, you are allowed to add any number of lines of code.\n",
        "\n",
        "The following question covers the California housing prices dataset and linear models in python. The dataset is taken from https://www.kaggle.com/camnugent/california-housing-prices/version/1. The categorical variables and rows with missing variables are removed to make it easier to run the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQphDrEczWoY"
      },
      "source": [
        "The data pertains to the houses found in a given California district and some summary stats about them based on the 1990 census data. The columns are as follows:\n",
        "\n",
        "* longitude\n",
        "* latitude\n",
        "* housingmedianage\n",
        "* total_rooms\n",
        "* total_bedrooms\n",
        "* population\n",
        "* households\n",
        "* median_income\n",
        "* medianhousevalue\n",
        "* ocean_proximity (this feature has been removed from the csv file since it is an ordinal variable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16G3O_XNzWoZ"
      },
      "source": [
        "NOTE\n",
        "* Only use the following code block if you are using Google Colab. If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
        "* It will prompt you to select a local file. Click on “Choose Files” then select and upload the file. Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "S2rMKQQgzWoZ",
        "outputId": "412f825a-4db6-4372-8e78-be0de61bd3a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2be02b6a-c055-46f9-a986-a4f09f51c64e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2be02b6a-c055-46f9-a986-a4f09f51c64e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving housing_data.csv to housing_data.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuWW6gn_zWoZ"
      },
      "source": [
        "Imports required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B21q-bx4zWoZ"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "df = pd.read_csv(\"housing_data.csv\")\n",
        "X = df.drop(['median_house_value'],axis=1)\n",
        "Y = df['median_house_value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj9kqISxzWoa",
        "outputId": "c468e372-a820-45db-c5a9-c1eed7086c39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
              "       'total_bedrooms', 'population', 'households', 'median_income',\n",
              "       'median_house_value', 'ocean_proximity'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show you all the columns in this file\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "plE_OXorzWoa",
        "outputId": "ce5a4335-6fe8-45a9-e8cb-3d43faaf4b5e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.23     37.88                41.0        880.0           129.0   \n",
              "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
              "2    -122.24     37.85                52.0       1467.0           190.0   \n",
              "3    -122.25     37.85                52.0       1274.0           235.0   \n",
              "4    -122.25     37.85                52.0       1627.0           280.0   \n",
              "\n",
              "   population  households  median_income  median_house_value ocean_proximity  \n",
              "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
              "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
              "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
              "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
              "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show you the first 5 rows in this file\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWVtzFlZzWoa"
      },
      "source": [
        "## Part-1: *(2 pts)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "altrF0ONzWoa"
      },
      "source": [
        "Split the data into a training set (75% of data) and a test set (25% of data), using the train_test_split function with random_state = 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZ0QGMfLzWoa"
      },
      "outputs": [],
      "source": [
        "##  START CODE  ## (1 line of code)\n",
        "X_train, X_test, y_train, y_test = None\n",
        "##  END CODE    ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p12PihqIzWoa"
      },
      "source": [
        "Scale the data (not including target) so that each of the independent variables would have zero mean and unit variance. You can use the sklearn.preprocessing.scale function for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyLKGFRtzWoa"
      },
      "outputs": [],
      "source": [
        "##  START CODE  ## (2 lines of code)\n",
        "Xscaled_train = None\n",
        "Xscaled_test = None\n",
        "##  END CODE    ##\n",
        "\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMIQVrijzWoa"
      },
      "source": [
        "Print the first 5 rows of the training set after scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiN26WrEzWoa"
      },
      "outputs": [],
      "source": [
        "##  START CODE  ##\n",
        "##  END CODE    ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWPxRJlVzWoa"
      },
      "source": [
        "Select any two variables. See how their histograms and scatterplots compare before and after scaling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62kY3ExAzWoa"
      },
      "outputs": [],
      "source": [
        "##  START CODE  ##\n",
        "##  END CODE    ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KawI2XbhzWob"
      },
      "source": [
        "> *Answer here*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHlAhbauzWob"
      },
      "source": [
        "## Part-2: *(5 pts)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RT99GSzzWob"
      },
      "source": [
        "Use `sklearn.linear_model.Lasso` and `sklearn.linear_model.Ridge` classes to do a 5-fold cross validation using sklearn's `KFold`. For the sweep of the regularization parameter, we will look at a grid of values ranging from  $\\alpha=10^{-6}$  to  $\\alpha=10^{6}$.In Python, you can consider this range of values as follows: `alpha = 10**numpy.linspace(-6, 6, 100)` so that you can generate 100 uniform values between -6 to 6 as power series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW5FcTDRzWob"
      },
      "source": [
        "Fit the 2 regression models (Lasso and Ridge) with scaled data and report the best chosen $\\alpha$ based on cross validation as well as the corresponding scoring metric. The cross validation should happen on your training data using MSE as the scoring metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE4l9nLEBo6z"
      },
      "outputs": [],
      "source": [
        "# Define number of folds\n",
        "##  START CODE  ## (1 line of code)\n",
        "n_folds = None\n",
        "##  END CODE  ##\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hTeW3JKF8ml"
      },
      "outputs": [],
      "source": [
        "# Create KFold from sklearn\n",
        "##  START CODE  ## (1 line of code)\n",
        "k_fold = None\n",
        "##  END CODE    ##\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjKRXwTFzWob"
      },
      "outputs": [],
      "source": [
        "#Define the alphas as defined in the question\n",
        "##  START CODE  ## (1 line of code)\n",
        "alphas = None\n",
        "##  END CODE    ##\n",
        "\n",
        "lasso_avg_mse = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-VBrbOnCgm4"
      },
      "outputs": [],
      "source": [
        "#For each value of alpha and each fold compute the mean square error\n",
        "for alpha in alphas:\n",
        "\n",
        "  #Instantiate a lasso model with the current alpha\n",
        "  ##  START CODE  ## (1 line of code)\n",
        "  lasso = None\n",
        "  ##  END CODE    ##\n",
        "\n",
        "  avg_mse = 0\n",
        "\n",
        "  for k, (train, test) in enumerate(k_fold.split(X_train, Y_train)):\n",
        "\n",
        "    #Fit the scaled training data to the lasso model\n",
        "    ## START CODE ## (1 line of code)\n",
        "\n",
        "    ## END CODE ##\n",
        "\n",
        "    #Calculate the average mean sqaured error\n",
        "    ##  START CODE  ## (1 line of code)\n",
        "    avg_mse = None\n",
        "    ##  END CODE    ##\n",
        "\n",
        "  # Take the average mean squared error as metric\n",
        "  lasso_avg_mse[alpha] = avg_mse / n_folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4CM_0joFe8S"
      },
      "outputs": [],
      "source": [
        "# Find the best value for alpha with minimum mean squared error\n",
        "##  START CODE  ## (1 line of code)\n",
        "best_alpha_lasso = None\n",
        "##  END CODE    ##\n",
        "\n",
        "print(\"Best lasso alpha: {}\".format(best_alpha_lasso))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXcr50EVG71p"
      },
      "outputs": [],
      "source": [
        "#For each value of alpha and each fold compute the mean square error\n",
        "for alpha in alphas:\n",
        "\n",
        "  #Instantiate a ridge model with the current alpha\n",
        "  ##  START CODE  ## (1 line of code)\n",
        "  ridge = None\n",
        "  ##  END CODE    ##\n",
        "\n",
        "  avg_mse = 0\n",
        "\n",
        "  for k, (train, test) in enumerate(k_fold.split(X_train, Y_train)):\n",
        "\n",
        "    #Fit the scaled training data to the ridge model\n",
        "    ## START CODE ## (1 line of code)\n",
        "\n",
        "    ## END CODE ##\n",
        "\n",
        "    #Calculate the average mean sqaured error\n",
        "    ##  START CODE  ## (1 line of code)\n",
        "    avg_mse = None\n",
        "    ##  END CODE    ##\n",
        "\n",
        "  # Take the average mean squared error as metric\n",
        "  ridge_avg_mse[alpha] = avg_mse / n_folds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1LiJKj3HRpV"
      },
      "outputs": [],
      "source": [
        "# Find the best value for alpha with minimum mean squared error\n",
        "##  START CODE  ## (1 line of code)\n",
        "best_alpha_ridge = None\n",
        "##  END CODE    ##\n",
        "\n",
        "print(\"Best Ridge alpha: {}\".format(best_alpha_ridge))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs4ytzCHzWob"
      },
      "source": [
        "## Part-3: *(7 pts)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebGlK_-KzWob"
      },
      "source": [
        "Run ridge and lasso regression for all of the $\\alpha$ specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; different features' weights of each model should be on the same plot with different colors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk560hkwzWob"
      },
      "outputs": [],
      "source": [
        "# Lasso Regression\n",
        "\n",
        "alphas = 10**np.linspace(6,-6,100)\n",
        "\n",
        "lasso = linear_model.Lasso(alpha=alpha)\n",
        "coefs = []\n",
        "\n",
        "for a in alphas:\n",
        "  #Specify current alpha as parameter for the lasso model\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##\n",
        "\n",
        "  #Fit the training data to the lasso model\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##\n",
        "\n",
        "  #Store learned coefficients in the coef variable\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFxhwgHNY1wL"
      },
      "outputs": [],
      "source": [
        "# Write the code to make the plot for coefficients learned from lasso\n",
        "## START CODE ##\n",
        "\n",
        "## END CODE ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRiJhDbCWHYJ"
      },
      "outputs": [],
      "source": [
        "# Ridge Regression\n",
        "\n",
        "alphas = 10**np.linspace(6,-6,100)\n",
        "\n",
        "ridge = linear_model.Ridge(alpha=alpha)\n",
        "coefs = []\n",
        "\n",
        "for a in alphas:\n",
        "  #Specify current alpha as parameter for the ridge model\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##\n",
        "\n",
        "  #Fit the training data to the ridge model\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##\n",
        "\n",
        "  #Store learned coefficients in the coef variable\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6mWtQWAY_05"
      },
      "outputs": [],
      "source": [
        "# Write the code to make the plot for coefficients learned from ridge\n",
        "## START CODE ##\n",
        "\n",
        "## END CODE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4ToCYI_zWob"
      },
      "source": [
        "What do you qualitatively observe when the value of the regularization parameter changes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGioS5clzWob"
      },
      "source": [
        "> *Answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNuyxETgzWoc"
      },
      "source": [
        "## Part-4: *(5 pts)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl4QyJ8RzWoc"
      },
      "source": [
        "Similarly, use `sklearn.linear_model.ElasticNet` to do linear regression with different $\\alpha$ values, and plot the coefficients learned for each of them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAb8VHJyzWoh"
      },
      "outputs": [],
      "source": [
        "# Ridge Regression\n",
        "\n",
        "alphas = 10**np.linspace(6,-6,100)\n",
        "\n",
        "ElastNet = linear_model.ElasticNet(alpha=alpha)\n",
        "coefs = []\n",
        "\n",
        "for a in alphas:\n",
        "  #Specify current alpha as parameter for the ElasticNet model\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##\n",
        "\n",
        "  #Fit the training data to the ElasticNet model\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##\n",
        "\n",
        "  #Store learned coefficients in the coef variable\n",
        "  ## START CODE ## (1 line of code)\n",
        "\n",
        "  ## END CODE ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiAe5JkaZTez"
      },
      "outputs": [],
      "source": [
        "# Write the code to make the plot for coefficients learned from ElasticNet\n",
        "## START CODE ##\n",
        "\n",
        "## END CODE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aPjEz4azWoh"
      },
      "source": [
        "Observe the plot, then explain the pros and cons of ridge, lasso and Elastic Net models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0VhGFq8zWoh"
      },
      "source": [
        "> *Answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsr0eyXxzWoi"
      },
      "source": [
        "## Part-5: *(10 pts)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oK1Mplulr9g"
      },
      "source": [
        "Run the following three regression models with MSE loss on the training data:\n",
        "\n",
        "a. linear regression without regularization\n",
        "\n",
        "b. linear regression with ridge regularization\n",
        "\n",
        "c. linear regression with lasso regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCgN_M8FmFy0"
      },
      "source": [
        "\n",
        "For part (b) and (c), use only the best regularization parameters. Report the MSE and R2 on the test data for each of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vInxZtUl01E"
      },
      "outputs": [],
      "source": [
        "## START CODE ##\n",
        "\n",
        "## END CODE ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaTLxColzWoi"
      },
      "source": [
        "## Part-6: *(3 pts)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyEUlDFEzWoi"
      },
      "source": [
        "Train the 3 models and report metrics with the original data without scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Abt6faNNzWoi"
      },
      "outputs": [],
      "source": [
        "##  START CODE  ##\n",
        "\n",
        "##  END CODE    ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjLMZ2DgzWoi"
      },
      "source": [
        "## Part-7: *(3 pts)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA_dCZlRzWoi"
      },
      "source": [
        "Why is it advisable to scale the independent variables when applying ridge or  lasso regression?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
